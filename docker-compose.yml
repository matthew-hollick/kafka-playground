version: '3.7'

services:
  zookeeper:
    image: zookeeper:3.4.9
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
        ZOO_MY_ID: 1
        ZOO_PORT: 2181
        ZOO_SERVERS: server.1=zookeeper:2888:3888

  kafka:
    image: confluentinc/cp-kafka:5.3.0
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.8.0
    hostname: elasticsearch
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - cluster.name=elasticsearch
      - bootstrap.memory_lock=true
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
    ulimits:
      memlock:
        soft: -1
        hard: -1

  kibana:
    image: docker.elastic.co/kibana/kibana:6.8.0
    hostname: kibana
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch

  logstash-producer:
    image: docker.elastic.co/logstash/logstash:7.3.1
    hostname: logstash-producer
    volumes:
      - ./logstash-producer/:/usr/share/logstash/pipeline/
    depends_on:
      - kafka

  logstash-consumer:
    image: docker.elastic.co/logstash/logstash:7.3.1
    hostname: logstash-consumer
    volumes:
      - ./logstash-consumer/:/usr/share/logstash/pipeline/
    depends_on:
      - elasticsearch
